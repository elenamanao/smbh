{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge PAO public data files in one file for the analysis\n",
    "\n",
    "A good part of this code is copied from the PAO public data release. Reference TO BE ADDED\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading, encapsulated to make it less installation and OS dependant\n",
    "import os.path\n",
    "from zipfile import ZipFile\n",
    "def AugerLoad(fdir,file):\n",
    "    \"\"\"\n",
    "    Loads a file from the auger open data release. Can be either in the local directory,\n",
    "    in the parent directory or in the augeropendata directory.\n",
    "    File is identified by it directory *fdir* and filename *file* and can be found in the directory\n",
    "    or in a zip file.\n",
    "    \"\"\"\n",
    "    for loc in [\".\",\"..\",\"augeropendata\"]:\n",
    "        fname=os.path.join(loc,fdir,file)\n",
    "        if os.path.isfile(fname):\n",
    "            print(f'Opening: {fname}. The file is unzipped')\n",
    "            return open(fname)\n",
    "        zname=os.path.join(loc,fdir+\".zip\")\n",
    "        if os.path.isfile(zname):\n",
    "            with ZipFile(zname) as myzip:\n",
    "                print(f'Opening: {fname}. The file is still zipped')\n",
    "                return myzip.open(os.path.join(fdir,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: ././dataSummarySD1500.csv. The file is unzipped\n",
      "Opening: ././dataSummaryInclined.csv. The file is unzipped\n"
     ]
    }
   ],
   "source": [
    "# open vertical and inclined events files\n",
    "\n",
    "sd1500_data = pd.read_csv(AugerLoad(\".\",\"dataSummarySD1500.csv\"))\n",
    "sdinclined_data = pd.read_csv(AugerLoad(\".\",\"dataSummaryInclined.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events before dropping the duplicates:\n",
      "SD1500: 24319\n",
      "Inclined: 2355\n",
      "Number of events after dropping the duplicates:\n",
      "SD1500: 24285\n",
      "Inclined: 2355\n"
     ]
    }
   ],
   "source": [
    "#drop duplicates\n",
    "\n",
    "print('Number of events before dropping the duplicates:')\n",
    "print('SD1500:', len(sd1500_data))\n",
    "print('Inclined:', len(sdinclined_data))\n",
    "\n",
    "sd1500_data = sd1500_data.drop_duplicates('id')\n",
    "sdinclined_data = sdinclined_data.drop_duplicates('id')\n",
    "\n",
    "print('Number of events after dropping the duplicates:')\n",
    "print('SD1500:', len(sd1500_data))\n",
    "print('Inclined:', len(sdinclined_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime(data):\n",
    "    event_id = data.id\n",
    "\n",
    "    # extract date and time from id using integer division // and modulus\n",
    "    year_factor = 10**10\n",
    "    day_factor =  10**7\n",
    "    day_modulus = 10**3\n",
    "    second_factor = 100\n",
    "    second_modulus = 10**5\n",
    "\n",
    "    years = event_id // year_factor\n",
    "    days = event_id // day_factor % day_modulus\n",
    "    seconds = event_id // second_factor % second_modulus\n",
    "    years = years + 2000\n",
    "\n",
    "    # generate a 'datetime' variable\n",
    "    # NB: the Auger day starts at noon UTC\n",
    "    date = [datetime.datetime(year, 1, 1, 12, tzinfo=datetime.timezone.utc) # initialise data at the beginning of the year\n",
    "            + datetime.timedelta(days=day - 1, seconds=second - 1)  #adds the additional days as read from the dataframe\n",
    "            for year, day, second in zip(years, days, seconds)]\n",
    "    # add the column 'date' to the dataframe\n",
    "    data['date']=date\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add datetime to the dataframes\n",
    "\n",
    "sd1500_data = get_datetime(sd1500_data)\n",
    "sdinclined_data = get_datetime(sdinclined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: ././auger_catalogSD.csv. The file is unzipped\n"
     ]
    }
   ],
   "source": [
    "# now we also load the UHECR catalog\n",
    "\n",
    "uhecr_data = pd.read_csv(AugerLoad(\".\",\"auger_catalogSD.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add datetime also to UHECR catalog\n",
    "\n",
    "id_array = uhecr_data.id\n",
    "\n",
    "date = []\n",
    "year = []\n",
    "month = []\n",
    "day = []\n",
    "for i in id_array:\n",
    "    date.append(i[3:])\n",
    "    year.append(int('20'+i[3:5]))\n",
    "    month.append(int(i[5:7]))\n",
    "    day.append(int(i[7:9]))\n",
    "\n",
    "utc_time = [datetime.datetime.fromtimestamp(t, tz=datetime.timezone.utc) for t in uhecr_data.utctime.values]\n",
    "\n",
    "uhecr_data['date'] = utc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the vertical events dataframe: Index(['id', 'sdid', 'gpstime', 'sd1500', 'multiEye', 'sd_gpsnanotime',\n",
      "       'sd_theta', 'sd_dtheta', 'sd_phi', 'sd_dphi', 'sd_energy', 'sd_denergy',\n",
      "       'sd_l', 'sd_b', 'sd_ra', 'sd_dec', 'sd_x', 'sd_dx', 'sd_y', 'sd_dy',\n",
      "       'sd_z', 'sd_easting', 'sd_northing', 'sd_altitude', 'sd_R', 'sd_dR',\n",
      "       'sd_s1000', 'sd_ds1000', 'sd_s38', 'sd_gcorr', 'sd_wcorr', 'sd_beta',\n",
      "       'sd_gamma', 'sd_chi2', 'sd_ndf', 'sd_geochi2', 'sd_geondf', 'sd_nbstat',\n",
      "       'fd_id', 'fd_gpsnanotime', 'fd_hdSpectrumEye', 'fd_hdCalibEye',\n",
      "       'fd_hdXmaxEye', 'fd_theta', 'fd_dtheta', 'fd_phi', 'fd_dphi', 'fd_l',\n",
      "       'fd_b', 'fd_ra', 'fd_dec', 'fd_totalEnergy', 'fd_dtotalEnergy',\n",
      "       'fd_calEnergy', 'fd_dcalEnergy', 'fd_xmax', 'fd_dxmax', 'fd_heightXmax',\n",
      "       'fd_distXmax', 'fd_dEdXmax', 'fd_ddEdXmax', 'fd_x', 'fd_dx', 'fd_y',\n",
      "       'fd_dy', 'fd_z', 'fd_easting', 'fd_northing', 'fd_altitude',\n",
      "       'fd_cherenkovFraction', 'fd_minViewAngle', 'fd_uspL', 'fd_duspL',\n",
      "       'fd_uspR', 'fd_duspR', 'fd_hottestStationId', 'fd_distSdpStation',\n",
      "       'fd_distAxisStation', 'sd_exposure', 'date'],\n",
      "      dtype='object')\n",
      "Columns in the inclined dataframe: Index(['id', 'sdid', 'gpstime', 'sd1500', 'multiEye', 'sd_gpsnanotime',\n",
      "       'sd_theta', 'sd_dtheta', 'sd_phi', 'sd_dphi', 'sd_energy', 'sd_denergy',\n",
      "       'sd_l', 'sd_b', 'sd_ra', 'sd_dec', 'sd_x', 'sd_dx', 'sd_y', 'sd_dy',\n",
      "       'sd_z', 'sd_easting', 'sd_northing', 'sd_altitude', 'sd_n19', 'sd_dn19',\n",
      "       'sd_n68', 'sd_dn68', 'sd_nbstat', 'sd_geondf', 'sd_geochi2',\n",
      "       'sd_exposure', 'date'],\n",
      "      dtype='object')\n",
      "Columns in the UHECR catalog dataframe: Index(['id', 'utctime', 'energy', 'denergy', 'theta', 'phi', 'ra', 'dec',\n",
      "       'risetime', 'drisetime', 'multiplicity', 'date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# now we select only the columns we are interested in and we make sure thay have the same name\n",
    "\n",
    "print('Columns in the vertical events dataframe:', sd1500_data.columns)\n",
    "\n",
    "print('Columns in the inclined dataframe:', sdinclined_data.columns)\n",
    "\n",
    "print('Columns in the UHECR catalog dataframe:', uhecr_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the columns we are interested in\n",
    "cols_sd = ['id', 'date', 'sd_energy', 'sd_denergy', 'sd_ra', 'sd_dec'  ]\n",
    "\n",
    "cols_UHECR = ['id', 'date', 'energy', 'denergy', 'ra', 'dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd1500_analysis_cols = sd1500_data[cols_sd].rename(columns = {'sd_energy': 'energy', 'sd_denergy': 'denergy','sd_ra': 'ra', 'sd_dec': 'dec'})\n",
    "sdinclined_analysis_cols = sdinclined_data[cols_sd].rename(columns = {'sd_energy': 'energy', 'sd_denergy': 'denergy','sd_ra': 'ra', 'sd_dec': 'dec'})\n",
    "uhecr_data_analysis_cols = uhecr_data[cols_UHECR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's delect the overlapping events\n",
    "overlap_sd1500 = np.intersect1d(sd1500_analysis_cols.date.values, uhecr_data_analysis_cols.date.values)\n",
    "\n",
    "mask = np.isin(sd1500_analysis_cols.date.values, overlap_sd1500)\n",
    "\n",
    "sd1500_analysis_cols = sd1500_analysis_cols[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we merge the events\n",
    "all_events_merged = pd.concat([sd1500_analysis_cols, sdinclined_analysis_cols, uhecr_data_analysis_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the file!\n",
    "cr_events = all_events_merged.to_records()\n",
    "\n",
    "np.save('cr_events.npy', cr_events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
